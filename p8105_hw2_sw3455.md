p8105_hw2_sw3455
================
Shiying Wu
2024-09-24

All the needed package will be download in here.

``` r
library(tidyverse)
library(readxl)
```

## Problem 1

``` r
Transit_df = 
  read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
        na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada) |>
  mutate(entry = ifelse(entry=="YES", TRUE, FALSE))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

For problem 1, after read
`NYC_Transit_Subway_Entrance_And_Exit_Data.csv` and noticed
`".", "NA", ""` would be missing value. I used clean_names() in janitor
package to clean the name. The dataset contain
`division, line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entrance_type, entry, exit_only, vending, staffing, staff_hours, ada, ada_notes, free_crossover, north_south_street, east_west_street, corner, entrance_latitude, entrance_longitude, station_location, entrance_location`.
According to Professor want focus on retain line, station, name, station
latitude / longitude, routes served, entry, vending, entrance type, and
ADA compliance, so I select
`line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada`
as my variable. I also mutate entry into factor by ifelse() function.
However, the data is not tidy due to not all station has as many as 11
routes which cause a lot of missing value in these observation, it could
be better represented if we pivot longer.

``` r
#Question 1
Transit_df |>
  distinct(line, station_name) |>
  nrow()
```

    ## [1] 465

``` r
#Question 2
Transit_df |>
  filter(ada == TRUE) |>
  distinct(line, station_name) |>
  nrow()
```

    ## [1] 84

``` r
#Question 3
mean(pull(Transit_df |> filter(vending == "NO"), entry), na.rm = TRUE)
```

    ## [1] 0.3770492

------------------------------------------------------------------------

- Q1: There are 465 distinct stations. I used the distinc() to find the
  table that contain distinct combination of line and station, then use
  nrow() to find how many distinct stations.

- Q2: There are 84 stations are ADA compliant. I used the filter() to
  find all the ADA compliant observation, then use as same as previous
  question, used distinc() contain distinct combination of line and
  station that with ADA compliant observation, then use nrow() to find
  how many distinct stations that are ADA compliant.

- Q3: The proportion of station entrances / exits without vending allow
  entrance is 0.3770492. I can use the mean on boolean, so I use the
  mean to find the proportion of entry. I pulled out the data while
  filter all the no vending station entrances / exits.

------------------------------------------------------------------------

``` r
#Reformat data so that route number and route name are distinct variables
Transit_df_long <- Transit_df |>
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11))|>
  pivot_longer(cols = starts_with("route"), 
               names_to = "route_number", 
               values_to = "route_name",
               values_drop_na = TRUE)

#distinct stations serve the A train
Transit_df_long |>
  filter(route_name == "A") |>
  distinct(line, station_name) |>
  nrow()
```

    ## [1] 60

``` r
#ADA compliant serve the A train
Transit_df_long |>
  filter(route_name == "A", ada == TRUE) |>
  distinct(line, station_name) |>
  nrow()
```

    ## [1] 17

There is 60 distinct stations serve the A train, and 17 ADA compliant
serve the A train.

## Problem 2

``` r
MrTrash_df = 
  read_excel("./data/202409 Trash Wheel Collection Data.xlsx",
  skip = 1, range = "A2:N653",
  sheet = "Mr. Trash Wheel") |>
  janitor::clean_names() |>
  mutate(sports_balls=round(sports_balls, digits = 0),
         sports_balls = as.integer(sports_balls),
         year = as.numeric(year),
         trash_wheel = "Mr. Trash Wheel") 

ProfTrash_df = 
  read_excel("./data/202409 Trash Wheel Collection Data.xlsx",
  skip = 1, range = "A2:M121",
  sheet = "Professor Trash Wheel") |>
  janitor::clean_names() |>
  mutate(trash_wheel = "Professor Trash Wheel") 

GTrash_df = 
  read_excel("./data/202409 Trash Wheel Collection Data.xlsx",
  skip = 1, range = "A2:L265",
  sheet = "Gwynnda Trash Wheel") |>
  janitor::clean_names() |>
  mutate(trash_wheel = "Gwynnda Trash Wheel") 

Trash_tidy = 
  bind_rows(MrTrash_df, ProfTrash_df, GTrash_df) |>
  relocate(trash_wheel) |>
  filter(!is.na(dumpster) & !is.na(date) & !is.na(weight_tons) & !is.na(volume_cubic_yards))

#total weight of trash collected by Professor Trash Wheel
sum(pull(ProfTrash_df, weight_tons), na.rm = TRUE)
```

    ## [1] 246.74

``` r
#total number of cigarette butts collected by Gwynnda in June of 2022
sum(pull(GTrash_df |>
           filter(year == 2022,
                  month == "June"), cigarette_butts))
```

    ## [1] 18120

The Trash Wheel data have 15 columns which means have 15 variables and
1032 rows means 1032 observations. The 15 variables are trash_wheel,
dumpster, month, year, date, weight_tons, volume_cubic_yards,
plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
plastic_bags, wrappers, sports_balls, homes_powered.

------------------------------------------------------------------------

- The trash_wheel variable is contain which trash wheel does dumpster
  belongs to which in this dataset would be categorical value,
  `Mr. Trash Wheel`, `Professor Trash Wheel`, and `Gwynnda Trash Wheel`.
  And the dumpster variable is number label of each dumpster for these
  trash wheel.

- The month, year, date variable are time variables for the time things
  in each dumpster to be recorded.

- The weight_tons variable recorded the total weight of trash in tons
  that each dumpster collected.

- The volume_cubic_yards variable recorded the total size of trash in
  cubic yards that each dumpster collected.

- The plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
  plastic_bags, wrappers, sports_balls, homes_powered variable recorded
  the total numbers of each specific trash collected.

The total weight of trash collected by Professor Trash Wheel is 246.74
The total number of cigarette butts collected by Gwynnda in June of 2022
is 1.812^{4}. We skip the first line in excel which is the photo, read
right sheet, and assigned proper range of each dataset. And use
janitor::clean_names() to clean name, use round() and as.integer() to
converts the number of sports balls to integer. After we rbind() all
three dataset and omit rows that do not include dumpster-specific data.

## Problem 3

``` r
bakers_df = 
  read_csv(file = "./data/gbb_datasets/bakers.csv",
        na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  separate(baker_name, into = c("first_name", "last_name"), sep = " ")
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df = 
  read_csv(file = "./data/gbb_datasets/bakes.csv",
        na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  mutate(first_name = ifelse(baker=='"Jo"', "Jo", baker))|>
  select(-baker)
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results_df = 
  read_csv(file = "./data/gbb_datasets/results.csv", 
           skip = 2,
           na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  mutate(first_name = ifelse(baker == "Joanne", "Jo", baker)) |>
  select(-baker)
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bake_off_tidy<- bakers_df |>
  full_join(results_df, by = c("first_name", "series")) |>
  full_join(bakes_df, by = c("first_name", "series", "episode")) |>
  mutate(baker = paste(first_name, last_name, sep=" ")) |>
  select(baker, baker_age, baker_occupation, hometown, series, episode, signature_bake, show_stopper,technical, result) |>
  arrange(series, episode, baker) 

write_csv(bake_off_tidy, "./data/gbb_datasets/bake_off_tidy.csv")
```

I used the read_csv() function to load the data and
janitor::clean_names() to clean variable names. By viewing three data, I
noticed that bakers.csv has the full name of baker, but other two
dataset only contain first name. Thus, for bakers.csv, I split the
baker’s name into first_name and last_name for easier merging. In
bakes.csv, I renamed columns and replaced the baker column with
first_name to match with other two datasets. During the time, I noticed
that “Jo” in bake.csv, Joanne in results.csv and Jo Wheatley in
baker.csv are same people, so I change the first name all equal to Jo.
Finally, I merged the datasets using common columns (first_name, series,
and episode) by full_join() and also merge first_name and last name
together in order to create a tidy dataset and select the order of
variable with a meaningful orders and delete first_name and last name as
we already has baker as baker name. Then I arrange the dataset with
order of series, episode, then baker’s name for easier understanding.
Then I exported data as bake_off_tidy.csv, to the gbb_datasets file. The
dataset contains baker, baker_age, baker_occupation, hometown, series,
episode, signature_bake, show_stopper, technical, result

``` r
bake_off_tidy|>
  filter(series %in% 5:10, result == "STAR BAKER"| result == "WINNER") |>
  select(series, episode, baker) |>
  mutate(series = paste("series", series, sep="_")) |>
  pivot_wider(names_from = series, values_from = "baker") |>
  knitr::kable()
```

| episode | series_5          | series_6       | series_7         | series_8             | series_9            | series_10            |
|--------:|:------------------|:---------------|:-----------------|:---------------------|:--------------------|:---------------------|
|       1 | Nancy Birtwhistle | Marie Campbell | Jane Beedle      | Steven Carter-Bailey | Manon Lagrave       | Michelle Evans-Fecci |
|       2 | Richard Burr      | Ian Cumming    | Candice Brown    | Steven Carter-Bailey | Rahul Mandal        | Alice Fevronia       |
|       3 | Luis Troyano      | Ian Cumming    | Tom Gilliford    | Julia Chernogorova   | Rahul Mandal        | Michael Chakraverty  |
|       4 | Richard Burr      | Ian Cumming    | Benjamina Ebuehi | Kate Lyon            | Dan Beasley-Harling | Steph Blackwell      |
|       5 | Kate Henry        | Nadiya Hussain | Candice Brown    | Sophie Faldo         | Kim-Joy Hewlett     | Steph Blackwell      |
|       6 | Chetna Makan      | Mat Riley      | Tom Gilliford    | Liam Charles         | Briony Williams     | Steph Blackwell      |
|       7 | Richard Burr      | Tamal Ray      | Andrew Smyth     | Steven Carter-Bailey | Kim-Joy Hewlett     | Henry Bird           |
|       8 | Richard Burr      | Nadiya Hussain | Candice Brown    | Stacey Hart          | Ruby Bhogal         | Steph Blackwell      |
|       9 | Richard Burr      | Nadiya Hussain | Andrew Smyth     | Sophie Faldo         | Ruby Bhogal         | Alice Fevronia       |
|      10 | Nancy Birtwhistle | Nadiya Hussain | Candice Brown    | Sophie Faldo         | Rahul Mandal        | David Atherton       |

I filtered series from 5 to 10 and all the result either equals to “STAR
BAKER” or “WINNER”, and select the value I need which are series episode
and name. Due to winner in 1-9 episode are “STAR BAKER” and winner in
last episode is “WINNER”, so I do not need result. Then I pivot it wider
to make episode as column and series and row, name as the value for
better reading experiance.

It does not seems to be any pattern in it, but the winner all got star
baker before, so for future winner prediction, we can based on people
who left with winning experience of star baker.

``` r
viewers_df <- read_csv("./data/gbb_datasets/viewers.csv", na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  pivot_longer(
    series_1:series_10,
    names_to = "series", 
    names_prefix = "series_",
    values_to = "viewers")
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(viewers_df, 10)|>
  knitr::kable()
```

| episode | series | viewers |
|--------:|:-------|--------:|
|       1 | 1      |    2.24 |
|       1 | 2      |    3.10 |
|       1 | 3      |    3.85 |
|       1 | 4      |    6.60 |
|       1 | 5      |    8.51 |
|       1 | 6      |   11.62 |
|       1 | 7      |   13.58 |
|       1 | 8      |    9.46 |
|       1 | 9      |    9.55 |
|       1 | 10     |    9.62 |

``` r
mean(pull(viewers_df |> filter(series == 1), 
          viewers),
     na.rm = TRUE)
```

    ## [1] 2.77

``` r
mean(pull(viewers_df |> filter(series == 5), 
          viewers),
     na.rm = TRUE)
```

    ## [1] 10.0393

I use read_csv() to import the viewer.csv and clean the name by janitor
package. I pivot it longer to make episode andseries both are column, so
we have all value in same column for better tidyness.

The average of the viewer for series 1 is 2.77. And The average of the
viewer for series 5 is 10.0393.
