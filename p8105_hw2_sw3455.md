p8105_hw2_sw3455
================
Shiying Wu
2024-09-24

All the needed package will be download in here.

``` r
library(tidyverse)
library(readxl)
```

## Problem 1

``` r
Transit_df = 
  read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
        na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada) |>
  mutate(entry = ifelse(entry=="YES", TRUE, FALSE))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

For problem 1, after read
`NYC_Transit_Subway_Entrance_And_Exit_Data.csv` and noticed
`".", "NA", ""` would be missing value. I used clean_names() in janitor
package to clean the name. The dataset contain
`division, line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entrance_type, entry, exit_only, vending, staffing, staff_hours, ada, ada_notes, free_crossover, north_south_street, east_west_street, corner, entrance_latitude, entrance_longitude, station_location, entrance_location`.
According to Professor want focus on retain line, station, name, station
latitude / longitude, routes served, entry, vending, entrance type, and
ADA compliance, so I select
`line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada`
as my variable. I also mutate entry into factor by ifelse() function.
However, the data is not tidy due to not all station has as many as 11
routes which cause a lot of missing value in these observation, it could
be better represented if we pivot longer.

``` r
#Question 1
Transit_df |>
  distinct(line, station_name) |>
  nrow()
```

    ## [1] 465

``` r
#Question 2
Transit_df |>
  filter(ada == TRUE) |>
  distinct(line, station_name) |>
  nrow()
```

    ## [1] 84

``` r
#Question 3
mean(pull(Transit_df |> filter(vending == "NO"), entry), na.rm = TRUE)
```

    ## [1] 0.3770492

|                                                                                                                                                                                                                                                                                                                                       |
|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| \* Q1: There are 465 distinct stations. I used the distinc() to find the table that contain distinct combination of line and station, then use nrow() to find how many distinct stations.                                                                                                                                             |
| \* Q2: There are 84 stations are ADA compliant. I used the filter() to find all the ADA compliant observation, then use as same as previous question, used distinc() contain distinct combination of line and station that with ADA compliant observation, then use nrow() to find how many distinct stations that are ADA compliant. |
| \* Q3: The proportion of station entrances / exits without vending allow entrance is 0.3770492. I can use the mean on boolean, so I use the mean to find the proportion of entry. I pulled out the data while filter all the no vending station entrances / exits.                                                                    |

``` r
#Reformat data so that route number and route name are distinct variables
Transit_df_long <- Transit_df |>
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11))|>
  pivot_longer(cols = starts_with("route"), 
               names_to = "route_number", 
               values_to = "route_name",
               values_drop_na = TRUE)

#distinct stations serve the A train
Transit_df_long |>
  filter(route_name == "A") |>
  distinct(line, station_name) |>
  nrow()
```

    ## [1] 60

``` r
#ADA compliant serve the A train
Transit_df_long |>
  filter(route_name == "A", ada == TRUE) |>
  distinct(line, station_name) |>
  nrow()
```

    ## [1] 17

There is 60 distinct stations serve the A train, and 17 ADA compliant
serve the A train.

## Problem 2

``` r
MrTrash_df = 
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
  skip = 1, range = "A2:N586",
  sheet = "Mr. Trash Wheel") |>
  janitor::clean_names() |>
  mutate(sports_balls=round(sports_balls, digits = 0),
         sports_balls = as.integer(sports_balls),
         year = as.numeric(year),
         trash_wheel = "Mr. Trash Wheel") 

ProfTrash_df = 
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
  skip = 1, range = "A2:M108",
  sheet = "Professor Trash Wheel") |>
  janitor::clean_names() |>
  mutate(trash_wheel = "Professor Trash Wheel") 

GTrash_df = 
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
  skip = 1, range = "A2:L157",
  sheet = "Gwynnda Trash Wheel") |>
  janitor::clean_names() |>
  mutate(trash_wheel = "Gwynnda Trash Wheel") 

Trash_tidy = 
  bind_rows(MrTrash_df, ProfTrash_df, GTrash_df) |>
  select(trash_wheel, everything())

#total weight of trash collected by Professor Trash Wheel
sum(pull(ProfTrash_df, weight_tons))
```

    ## [1] 216.26

``` r
#total number of cigarette butts collected by Gwynnda in June of 2022
sum(pull(GTrash_df |>
           filter(year == 2022,
                  month == "June"), cigarette_butts))
```

    ## [1] 18120

The Trash Wheel data have 15 columns which means have 15 variables and
845 rows means 845 observations. The 15 variables are trash_wheel,
dumpster, month, year, date, weight_tons, volume_cubic_yards,
plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
plastic_bags, wrappers, sports_balls, homes_powered.

------------------------------------------------------------------------

- The trash_wheel variable is contain which trash wheel does dumpster
  belongs to which in this dataset would be categorical value,
  `Mr. Trash Wheel`, `Professor Trash Wheel`, and `Gwynnda Trash Wheel`.
  And the dumpster variable is number label of each dumpster for these
  trash wheel.

- The month, year, date variable are time variables for the time things
  in each dumpster to be recorded.

- The weight_tons variable recorded the total weight of trash in tons
  that each dumpster collected.

- The volume_cubic_yards variable recorded the total size of trash in
  cubic yards that each dumpster collected.

- The plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
  plastic_bags, wrappers, sports_balls, homes_powered variable recorded
  the total numbers of each specific trash collected.

The total weight of trash collected by Professor Trash Wheel is 216.26
The total number of cigarette butts collected by Gwynnda in June of 2022
is 1.812^{4}.

## Problem 3

``` r
bakers_df = 
  read_csv(file = "./data/gbb_datasets/bakers.csv",
        na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  separate(baker_name, into = c("first_name", "last_name"), sep = " ")
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df = 
  read_csv(file = "./data/gbb_datasets/bakes.csv",
        na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  mutate(first_name = baker) |>
  select(-baker)
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results_df = 
  read_csv(file = "./data/gbb_datasets/results.csv", skip = 2,
        na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  mutate(first_name = baker) |>
  select(-baker)
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bake_off_tidy<- bakers_df |>
  left_join(results_df, by = c("first_name", "series")) |>
  left_join(bakes_df, by = c("first_name", "series", "episode")) |>
  relocate(first_name, last_name, baker_age, baker_occupation, hometown, series, episode, signature_bake, show_stopper, result) |>
  arrange(series, episode, first_name)
  

write_csv(bake_off_tidy, "./data/gbb_datasets/bake_off_tidy.csv")
```

I used the read_csv() function to load the data and
janitor::clean_names() to clean variable names. By viewing three data, I
noticed that bakers.csv has the full name of baker, but other two
dataset only contain first name. Thus, for bakers.csv, I split the
baker’s name into first_name and last_name for easier merging. In
bakes.csv, I renamed columns and replaced the baker column with
first_name to match with other two datasets. Finally, I merged the
datasets using common columns (first_name, series, and episode) by
left_join() to create a tidy dataset and relocate the order of variable
with a meaningful orders. Thenn I arrange the dataset with order of
series, episode, then baker’s name for easier understanding. Then I
exported data as bake_off_tidy.csv, to the gbb_datasets file. The
dataset contains line, station_name, station_latitude,
station_longitude, route1, route2, route3, route4, route5, route6,
route7, route8, route9, route10, route11, entry, vending, entrance_type,
ada

``` r
bake_off_tidy|>
  filter(series %in% 5:10, result == "STAR BAKER"|result == "WINNER")
```

    ## # A tibble: 60 × 11
    ##    first_name last_name   baker_age baker_occupation     hometown series episode
    ##    <chr>      <chr>           <dbl> <chr>                <chr>     <dbl>   <dbl>
    ##  1 Nancy      Birtwhistle        60 Retired Practice Ma… Barton-…      5       1
    ##  2 Richard    Burr               38 Builder              Mill Hi…      5       2
    ##  3 Luis       Troyano            42 Graphic Designer     Poynton…      5       3
    ##  4 Richard    Burr               38 Builder              Mill Hi…      5       4
    ##  5 Kate       Henry              41 Furniture Restorer   Brighto…      5       5
    ##  6 Chetna     Makan              35 Fashion Designer     Broadst…      5       6
    ##  7 Richard    Burr               38 Builder              Mill Hi…      5       7
    ##  8 Richard    Burr               38 Builder              Mill Hi…      5       8
    ##  9 Richard    Burr               38 Builder              Mill Hi…      5       9
    ## 10 Nancy      Birtwhistle        60 Retired Practice Ma… Barton-…      5      10
    ## # ℹ 50 more rows
    ## # ℹ 4 more variables: signature_bake <chr>, show_stopper <chr>, result <chr>,
    ## #   technical <dbl>

It does not seems to be any pattern in it, but the winner all got star
baker before, so for future winner prediction, we can based on people
who left with winning experience of star baker.

``` r
viewers_df <- read_csv("./data/gbb_datasets/viewers.csv", na = c(".", "NA", "")) |>
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(viewers_df, 10)
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

``` r
mean(viewers_df$series_1, na.rm = TRUE)
```

    ## [1] 2.77

``` r
mean(viewers_df$series_5, na.rm = TRUE)
```

    ## [1] 10.0393

The average of the viewer for series 1 is 2.77. And The average of the
viewer for series 5 is 10.0393.
